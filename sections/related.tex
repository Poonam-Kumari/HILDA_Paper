% -*- root: ../paper.tex -*-

Data distributions have been used for similar purposes in other work.  
For example GestureQuery~\cite{nandi2013gestural} uses data similarity between two attributes to select candidate attributes for an equi-join.  
To maximize the join arity, the system counts the number of times each value from one attribute appears in the other and a histogram is constructed from the counts for all of the values.

Wrangler \cite{kandel2011wrangler} and Potter's wheel \cite{raman2001potter} detect data domains through inclusion functions (e.g. regular expressions).
Wrangler in particular infers the data type of a column and highlights errors based on inconsistent data types. 
Wrangler also has several operators like split and unfold that create new columns.
The split operator decomposes composite data values into component distributions.  
The unfold operator reverses a table pivot, collapsing data laid out as key-value pairs into columns.  
A useful application of the \systemname knowledge-base that we hope to explore in future work is using it to detect opportunities for applying such operators.

% Although wrangler creates a new column for extracted data as part of unfold operation, but does not infer the column name, analyst has to name the new column manually.
% Unfold operation ”unflattens” tables; it takes two columns, collects rows that have the same values for all the other columns, and unfolds the two chosen columns. Values in one column are used as column names to align the values in the other column.

An orthogonal approach to modeling and matching columns is to use ontologies, which express entities, facts, relations between facts and properties of relations
Ontologies like Yago \cite{fabian2007yago} could be used to identify semantic properties that relate columns.

A data summary called the data describer is used in \cite{ping2017datasynthesizer}. The data types, correlations and distributions of the attributes in a private dataset are listed. Each attribute is categorized into either numerical or non-numerical. If non-numerical attribute cannot be parsed as datetime then it is considered to be a string.

Data describer takes in a CSV file and infers the data types and domains. The attribute datatypes are parsed as numerical, datetime or string. We are inferring the datatypes as well. When run in correlated attribute mode, data describer provides corelation between attributes. We could use this functionality in LOKI.
\todo{What exactly is the purpose of the data describer.  How is it used?  How do its goals differ from ours, and what are the implications on its design?} 

PADS \cite{fisher2005pads} helps users to understand the layout and meaning of data by designing syntactic descriptions of the data.
Based on the syntax, accumulators track the number of good values, the number of bad values, and the distribution of legal values.
This technique could be used in \systemname to help capture expert knowledge.

There is an increasing number of datasets in which well-structured attributes
(with or without a name) can be identified, each containing a set of values called a domain. There is lack of schema description in most of the datasets.
LSH Ensemble is used in \cite{zhu2016lsh} to find domains that maximally contain a query dataset, which can help to find datasets that best augment a given set of data.