% -*- root: ../paper.tex -*-

It's a story as old as time: A student gathers data, makes a graph with the data, writes a paper about the data.
Then the student graduates and the data languishes, without so much as a wiki page or README file documenting it.
The next student to use the data needs to spend hours, days, or even weeks reverse-engineering it.
Then they also graduate and the whole process can start over again.

This tragic cycle of data abandonment must be broken.
We propose to end the suffering with \emph{Label Once, and Keep It} (\systemname), a data-ingest middleware for incremental, re-usable schema recovery.
When a user first points \systemname at a new tabular data set, \systemname proposes a schema for it.
It then collects feedback, both learning and also preserving schema metadata for later use.
In short, \systemname will allow users to assemble schemas on-demand, both (re-)discovering and incrementally refining schema definitions in response to changing data needs.
However, to accomplish this, we first need a knowledge-base of heuristics, domain knowledge, and dirty tricks.

In this paper, we outline an interactive editor that we are designing as part of \systemname to facilitate the construction of such a knowledge-base
The \systemname editor allows knowledge to be incorporated into the knowledge-base in two ways: (1) By learning from example data (e.g., drawn from open data portals), and (2) By manual adjustment from domain experts.
In particular, we focus on our preliminary work to streamline manual refinement of knowledge learned from one type of example data.
We show how, the editor can be used to help experts to quickly identify and resolve errors and ambiguity in the \systemname knowledge-base.
Concretely, the contributions of this paper include:
\begin{enumerate*}
  \item We introduce \systemname in Section~\ref{sec:system} and detail the structure of its knowledge-base in Section~\ref{sec:knowledgebase}
  \item We illustrate how the \systemname editor pre-populates the knowledge-base by learning from example data in Section~\ref{sec:trainbyexample}.
  \item We identify specific errors that arise in the training process and show how the \systemname editor facilitates efficient detection and manual repair of the error.
\end{enumerate*}

% One more thought regarding a pitch for the work.  We could wrap the idea in the context of a larger system for importing / querying initially unlabeled data.  Specifically, when someone first loads an unlabeled (or only partially labeled) CSV file into a database/spark, they have two problems:

% 1) They need to label a subset of the columns that pertain to the specific analysis they want to do now.
% 2) They don't need to label *all* of the columns (might be 10s, 100s, or 1000s of columns that they don't care about).  

% However, at some point in the future, more labeling might be helpful.  For example:
% 1) They pose a query and randomly discover that they are missing a column that *could* potentially exist in the source data.
% 2) Someone else wants to use the same data set, but with a different selection of columns.
% 3) The knowledge-base is updated and more automatic labelings become available.

% I'm going to suggest that we present our contribution in the context of a system that:
% 1) Auto-suggests names for columns based on existing heuristics
% 2) Saves labeling efforts, making it possible to incrementally label a data-set and re-use effort across analyses
% 3) Allows you to ask whether a particular column name *could* exist in a given data set, and identify the data column that most-likely represents it.

% Specifically, in this paper, we're conducting a case study evaluating one particular approach to task (1).  