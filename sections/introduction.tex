% -*- root: ../paper.tex -*-

It's a story as old as time: A student gathers data, makes a graph with the data, writes a paper about the data.
Then the student graduates and the data languishes, without so much as a wiki page or README file documenting it.
The next student to use the data needs to spend hours, days, or even weeks reverse-engineering it.
Then they also graduate and the whole process can start over again.

This tragic cycle of data abandonment must be broken.
We propose to end the suffering with \emph{Label Once, and Keep It} (\systemname), a data-ingest middleware for incremental, re-usable schema recovery.
When a user first points \systemname at a new tabular data set, \systemname proposes a schema for it.
It then collects feedback, both learning and also preserving schema metadata for later use.
In short, \systemname will allow users to assemble schemas on-demand, both (re-)discovering and incrementally refining schema definitions in response to changing data needs.
However, to accomplish this, we first need a knowledge-base of heuristics, domain knowledge, and dirty tricks.

In principle, we might implement such a knowledge base as a neural network, train it on example data, and use it to suggest schemas.
However, this approach suffers from a host of limitations:
\begin{enumerate*}
\item \textbf{Lack of generality}: A neural network tuned for use with one type of training data may need to be retuned for other scenarios.
\item \textbf{Lack of extensibility}: Adding new training data or knowledge requires retraining from scratch.
\item \textbf{Lack of transparency}: If the network misclassifies a column name, it can be hard to debug and refine the result.
\end{enumerate*}
Instead, we opt for an interactive approach.  We present the \systemname knowledge-base, a flexible, extensible infrastructure for collecting schema-naming heuristics.  
We show how simple, efficient off-the-shelf techniques can be used to quickly prime the knowledge-base using example data.
Then, we introduce an interactive editor that we are designing as part of \systemname to allow domain experts to refine the knowledge-base.
In particular, we focus on our preliminary work to streamline manual refinement of knowledge learned from one type of example data.
We show how, the editor can be used to help experts to quickly identify and resolve errors and ambiguity in the \systemname knowledge-base.

Concretely, the contributions of this paper include:
\begin{enumerate*}
  \item We introduce \systemname in Section~\ref{sec:system} and detail the structure of its knowledge-base in Section~\ref{sec:knowledgebase}.
  \item We illustrate how the \systemname editor pre-populates the knowledge-base by learning from example data in Section~\ref{sec:trainbyexample}.
  \item We identify specific errors that arise in the training process and show how the \systemname editor facilitates efficient detection and manual repair of the error in Section~\ref{sec:expertui}.
\end{enumerate*}

% One more thought regarding a pitch for the work.  We could wrap the idea in the context of a larger system for importing / querying initially unlabeled data.  Specifically, when someone first loads an unlabeled (or only partially labeled) CSV file into a database/spark, they have two problems:

% 1) They need to label a subset of the columns that pertain to the specific analysis they want to do now.
% 2) They don't need to label *all* of the columns (might be 10s, 100s, or 1000s of columns that they don't care about).  

% However, at some point in the future, more labeling might be helpful.  For example:
% 1) They pose a query and randomly discover that they are missing a column that *could* potentially exist in the source data.
% 2) Someone else wants to use the same data set, but with a different selection of columns.
% 3) The knowledge-base is updated and more automatic labelings become available.

% I'm going to suggest that we present our contribution in the context of a system that:
% 1) Auto-suggests names for columns based on existing heuristics
% 2) Saves labeling efforts, making it possible to incrementally label a data-set and re-use effort across analyses
% 3) Allows you to ask whether a particular column name *could* exist in a given data set, and identify the data column that most-likely represents it.

% Specifically, in this paper, we're conducting a case study evaluating one particular approach to task (1).  