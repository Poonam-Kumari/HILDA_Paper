% -*- root: ../paper.tex -*-

The core component of \systemname is a knowledge-base that is used to identify column names.
In this section, we outline the key design challenges and capabilities of this knowledge-base.  
We first outline the two types of information being stored: Heuristics and Feedback.
Then we discuss both heuristics and feedback for one particular type of data: Numerical.  
Finally, we discuss support for both labeling and discovery queries over over the knowledge-base.

\subsection{Modeling Column Descriptions}

The \systemname knowledge-base is responsible for answering both labeling and discovery queries.
For both we want to define a $[0,1]$-valued measure that we call the \emph{match-quality}: the quality of a match between a column name and a collection of data values in the column.
A match-quality of 0 indicates that the name is completely inappropriate for the column, while a match-quality of 1 indicates a perfect match.  
The \systemname knowledge-base is responsible for associating column names with match-quality functions for computing the descriptiveness of the name on a given column.
We will abuse syntax and use $\namesymbol$ to denote both the name, as well as the corresponding match-quality function ($\namesymbol : dom_T(A) \rightarrow [0,1]$) in the knowledge-base.

\begin{figure}
\placeholder{put bar-graph of types here}
\caption{Breakdown of data types}
\label{fig:type-breakdown}
\end{figure}

To instantiate specific match-quality functions, we merge three sources of information: Learned Heuristics, Expert Augmentations, and User Feedback. 
The first category, learned heuristics, models the content and distribution of typical instances of columns with a similar name.
This distribution serves as a baseline match-quality function.
The second category, expert augmentations, modifies the first, increasing or decreasing values based on expert-provided descriptions of what should and should not appear in columns with this name.
The final category, user feedback, provides users with a way to confirm or override automated system choices, while also preserving these associations for future use.

\subsection{Learned Heuristics}
Learned heuristics serve as baseline match-quality functions by modeling typical instances of columns.
Specific modeling techniques vary by data type, so our first step was to assess what types exist.
We sampled a collection of \placeholder{\#\#\#} data sets from open data portals, as discussed later in Experiments (Section~\ref{sec:experiments}).
We then categorized the \placeholder{\#\#\#} columns in our sample into three broad types: 
(1) Numeric data, or any records consisting of digits, at most a single decimal point, and an optional exponent; 
(2) Enumerated types, based on an arbitrary threshold of 100 distinct values in the column; and 
(3) Textual data, or anything else.  
By far, the dominant type was numeric, so the preliminary efforts we outline in this paper focus on modeling numeric data.

\tinysection{Numeric Data}
We considered a range of options for modeling numeric data and settled on an approach based on numerical distributions.
In comparison to more complex approaches like neural networks, this approach is simple, efficient, and well understood.
Simply put, given a number of example column instances, we explore a range of numerical distributions and select the one with the best fit.
Our preliminary implementation of \systemname explores three different distributions: Uniform, Normal, and \placeholder{Zipfian}\footnote{As we show in the experiments section, these three distributions are sufficient to describe the vast majority of data in our sample set.}.  
For each distribution, we find the parameters ($\ell,h,\mu,\sigma,a$) that minimize the root-mean-squared (RMS) error between the predicted and observed frequencies. 
\todo{Gourab, please sanity check the above.  Are we doing anything like binning to smooth out the curve?}
$$\mathbb U(\ell, h)\;\;\;\;\;\mathbb N(\mu, \sigma)\;\;\;\;\;\mathbb Z(a)$$
We then select the one model with the lowest overall RMS error.

The resulting match-quality function is the probability of the column values being a representative sample drawn from this distribution.
We measure this probability by the \placeholder{RMS Error} between the distribution of the sampled values and the distribution modeling the name.

\subsection{Expert Augmentation}
Learned heuristics in the \systemname knowledge-base provide a starting point for defining match-quality functions.
To fine tune these match-quality functions, we provide support for augmenting matching-quality functions in the knowledge base with expert knowledge.

\begin{figure}
\begin{tabular}{r|l}
\textbf{How Y modifies X} & $(\namesymbol_x \oplus \namesymbol_y)(T_A)$ \\\hline
X Or Y & $max(\namesymbol_x(T_A), \namesymbol_y(T_A))$\\
X And Y & $\namesymbol_x(T_A) \cdot \namesymbol_y(T_A)$\\
X Unless Y & $min(\namesymbol_x(T_A), \namesymbol_y(T_A))$\\
Y Instead of X & $\namesymbol_y(T_A)$\\
Y Suggests X & $1-(1-\namesymbol_x(T_A))(1-\namesymbol_y(T_A))$
\end{tabular}
\caption{Example augmentation modifiers}
\label{fig:modifiers}
\end{figure}

\tinysection{Modifiers}
Expert knowledge in the knowledge-base is encoded in two parts: 
(1) A quality-match function that provides a heuristic encoding of the expert knowledge, and 
(2) An augmentation modifier that indicates how the new quality match function is to be combined with the existing one.  
Figure~\ref{fig:modifiers} illustrates several example modifiers together with intuitive phrasings of each.  
For example, if the expert heuristic defines an unrelated approach to matching columns, the highest match value is used.

\subsection{Feedback}

Outline exact matching rules: Data identity, recording/querying feedback.  Merging conflicts.

\begin{itemize}
  \item How is feedback saved in the KB.
  \item What happens in response to conflicting feedback.  
\end{itemize}



\subsection{Labeling Queries}

\subsection{Discovery Queries}
